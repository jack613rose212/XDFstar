### 一、go语言基础知识

#### 1.解释make和new的区别

二者都是内存的分配（堆上），但是make只用于slice、map以及channel的初始化（非零值）；而new用于类型的内存分配，并且内存置为零。所以在我们编写程序的时候，就可以根据自己的需要很好的选择了。

==make返回的还是这三个引用类型本身；而new返回的是指向类型的指针。==



#### 2.解释Slice和Array的区别

array是固定长度的数组，使用前必须确定数组长度

slice是一个引用类型，是一个动态的指向数组切片的指针。

slice是一个不定长的，总是指向底层的数组`array`的数据结构。

==数组是值类型，把一个数组赋予给另一个数组时是发生值拷贝，而切片是指针类型，拷贝的是指针。所以在golang的方法中即使是值传递切片，其实也是传递的指针。==

数组大小是固定的，切片大小不是。在运行时可以动态地增加或减少切片的大小，但数组不可以。切片类似于链表，可以向切片push，pop数据，实现FIFO，LIFO。使用了内置的添加、复制功能对切片操作。



#### 3.Golang采用什么Gc算法

golang的垃圾回收采用的是 标记-清理（Mark-and-Sweep） 算法

就是先标记出需要回收的内存对象快，然后在清理掉；

基于1.4版本的，GC过程在标记过程是（STW）的

在1.5版本里面对GC做了很大的优化；采用三色标记，将标记过程细化成三段，只有前后的两段是stw（ stop the world)）的；极大地缩短了gc的stw时间

> Go语言的内存管理看成一个两级的内存管理结构，MHeap和MCache。上面一级管理的基本单位是页，用于分配大对象（大于 32K），每次分配都是若干连续的页，也就是若干个4KB的大小。使用的数据结构是MHeap和MSpan，用BestFit算法做分配，用位示图做回收（标记清扫算法）。下面一级管理的基本单位是不同类型的固定大小的对象（每个系统线程分配的一个本地MCache），更像一个对象池而不是内存池，用引用计数做回收。



#### 4.有缓存和无缓存channel的区别

无缓冲channel：

接收前没有能力保存任何数据的通道。要求发送goroutine和接收goroutine同时准备好，才能完成发送和接收操作。

否则，通道会导致先执行发送或接收操作的 goroutine 阻塞等待。

通常对应 同步操作。会发生阻塞。

有缓冲channel：

在接收前能存储一个或者多个数据值的通道。不强制要求 goroutine 之间必须同时完成发送和接收。

只有通道中没有要接收的值时，接收端才会阻塞。只有通道没有可用缓冲区容纳被发送的数据时，发送端才会阻塞。

通常对应 异步操作。会发生阻塞。	



#### 5.如何关闭channel？请用代码说明。

```go
ch := make(chan bool) 
close(ch)

判断channel关闭的方法：
方法一： if value，ok=<-ch；ok==true{}
//1.如果写端没有写数据，也没有关闭。<-ch；会阻塞
//2.如果写端写数据 value保存<-ch独到的数据。ok被设置为true
//3.如果写端关闭。value为数据的默认值，ok被设置为false
//对于一个已经关闭的channel写操作报错，读操作不报错，会读到数据类型的默认值
方法二： for num：=range ch{
}//简单判断channel关闭
```



#### 6.下面这个程序的现象

```go
func main(){
  select()
}

//select{}是一个没有任何case的select，它会一直阻塞


// select 是 Go 提供的一个关键字。可以监听channel上的数据流动。
//select的语法与switch类似。每个选择条件由case来描述。
//每次执行一个case分支
//通常将select放置到循环中去
//每个case语句里必须是一个IO操作。
//select 通常对应一个异步事件处理。
//可以利用select来设置超时。
//如果监听中的case不满足--当前case阻塞
//如果监听中的case同时有多个满足，select选择任意一个执行
//select语法中的default是在所有case不满足情况的条件下，设置的默认处理动作。通常不设置，防止忙轮询消耗系统资源。
//break只能跳出一个case分支不能跳出select外面的for
```



#### 7.简述读写锁、互斥锁，以及在go语言中的使用场景

Mutex为互斥锁，Lock()加锁，Unlock()解锁，使用Lock()加锁后，便不能再次对其进行加锁，直到利用Unlock()解锁对其解锁后，才能再次加锁．适用于读写不确定场景，即读写次数没有明显的区别，并且只允许只有一个读或者写的场景，所以该锁叶叫做全局锁。 

互斥锁访问共享数据之前，加锁，加锁成功之后在对共享资源进行访问。共享资源访问结束，立即解锁。没有加锁成功，阻塞在锁上。

读写锁实际是一种特殊的自旋锁，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。这种锁相对于自旋锁而言，能提高并发性，因为在多处理器系统中，它允许同时有多个读者来访问共享资源，最大可能的读者数为实际的逻辑CPU数。写者是排他性的，一个读写锁同时只能有一个写者或多个读者（与CPU数相关），但不能同时既有读者又有写者。

读共享，写独占。写锁优先级高。对共享数据的保护。防止出现数据混淆。读操作，不会对共享数据进行修改。因此多个go程同时读，不会出现数据混乱，一个读写锁有两种属性r，w。加锁锁定共享数据时要指定属性。

==在加锁的时候每个进程都要上锁==

#### 8.如何定义和使用接口？

接口类型具体描述了一系列方法的集合，一个实现了这些方法的具体类型是这个接口类型的实例。
一个类型如果拥有一个接口需要的所有方法，那么这个类型就实现了这个接口。
以 `type 接口名 interface { 函数签名; ... }` 进行定义



#### 9.一个通过make()命令创建的缓冲区被分配了一块内存后。如何销毁缓冲区并收回内存？

​	buffer = nil
	在运行时，buffer = nil将启动垃圾回收。



#### 10.cap()和len()函数的区别是什么？

​	len()返回切片中的元素个数。
	cap()返回切片的容量即切片可以容纳的元素数量。



#### 11.哈希表或哈希映射允许快速查找。GO如何实现哈希映射？

​	哈希表在Golang中相当于map，也就是哈希映射。
	hash-table := make(map[string]string)



#### 12.Go语言如何处理异常？

Go的类型系统会在编译时捕获很多错误，但有些错误只能在运行时检查，如数组访问越界、空指针引用等。
这些运行时错误会引起painc异常。
如果在deferred函数中调用了内置函数recover，并且定义该defer语句的函数发生了panic异常，recover会使程序从panic中恢复，并返回panic value。导致panic异常的函数不会继续运行，但能正常返回。在未发生panic时调用recover，recover会返回nil。



#### 13.golang中的引用类型有哪些？

​	引用类型包括，切片，map，channel和interface



#### 14.Gpm调度机制？

Go并发调度: G-P-M模型，

G：Goroutine的简称，上面用go关键字加函数调用的代码就是创建了一个G对象，是对一个要并发执行的任务的封装，也可以称作用户态线程。属于用户级资源，对OS透明，具备轻量级，可以大量创建，上下文切换成本低等特点。
M：Machine的简称，在linux平台上是用clone系统调用创建的，其与用linux pthread库创建出来的线程本质上是一样的，都是利用系统调用创建出来的OS线程实体。M的作用就是执行G中包装的并发任务。**Go运行时系统中的调度器的主要职责就是将G公平合理的安排到多个M上去执行**。其属于OS资源，可创建的数量上也受限了OS，通常情况下G的数量都多于活跃的M的。
P：Processor的简称，逻辑处理器，主要作用是管理G对象（每个P都有一个G队列），并为G在M上的运行提供本地化资源。

G:代表一个goroutine，它有自己的栈;
P:process 是  G-M 的中间层，组织多个 goroutine 跑在同一个 线程上。   数量由 GOMAXPROCS 设置
M:M代表内核级线程，一个M就是一个线程，goroutine就是跑在M之上的；
Sched：代表调度器，它维护有存储M和G的队列
（人、推车、砖头）

1.一个 P 上会挂着多个 G，当一个 G 执行结束时，P 会选择下一个 G 继续执行。
2.每有一个go语句被执行，runqueue队列就在其末尾加入一个goroutine
3.P所分配的任务G很快就执行完了，那么P不得不从其他的P里拿一些G来执行
4.scheduler 除了在一个 goroutine 执行结束时会调度后面的 goroutine 执行，还会在正在被执行的 goroutine 发生以下情况时让出当前 goroutine 的执行权，并调度后面的 goroutine 执行：IO 操作、Channel 阻塞、运行较长时间



#### 15.Map的线程安全？

利用读写锁：

```
var counter = struct{
    sync.RWMutex
    m map[string]int
}{m: make(map[string]int)}
```

它使用嵌入struct为map增加一个读写锁。

读数据的时候很方便的加锁：

```
counter.RLock()
n := counter.m["some_key"]
counter.RUnlock()
fmt.Println("some_key:", n)
```

写数据的时候:

```
counter.Lock()
counter.m["some_key"]++
counter.Unlock()
```

#### 16.panic 被引发到程序终止运行的大致过程

某个函数中的某行代码有意或无意地引发了一个 panic。这时，初始的 panic 详情会被建立起来，并且该程序的控制权会立即从此行代码转移至调用其所属函数的那行代码上，也就是调用栈中的上一级。
这也意味着，此行代码所属函数的执行随即终止。紧接着，控制权并不会在此有片刻停留，它又会立即转移至再上一级的调用代码处。控制权如此一级一级地沿着调用栈的反方向传播至顶端，也就是我们编写的最外层函数那里。
这里的最外层函数指的是函数，对于主 goroutine 来说就是函数。但是控制权也不会停留在那里，而是被 Go 语言运行时系统收回。
随后，程序崩溃并终止运行，承载程序这次运行的进程也会随之死亡并消失。与此同时，在这个控制权传播的过程中，panic 详情会被逐渐地积累和完善，并会在程序终止之前被打印出来。

#### 17.go代码的执行顺序

![go代码的执行顺序](http://upload-images.jianshu.io/upload_images/16466395-646b30864d848342.png)

#### 18.defer的执行顺序

> defer执行顺序为先进后出

#### 19.go线程同步一般通过那几个方式实现

1. Sleep 
2. 管道实现同步
3. sync.WaitGroup
4. 加锁操作

#### 20.等待所有的 goroutine 都执行完毕时再退出 

1. channel 进行同步 

   > 这种方法需要知道子 goroutine 的个数 

2. sync.WaitGroup 

   > 不需要知道 gotoutine 的个数 



#### 21.go build和go install的区别

**go build** 

> 通过go build加上要编译的Go源文件名，我们即可得到一个可执行文件，默认情况下这个文件的名字为源文件名字去掉.go后缀。 

**go install**

> 与build命令相比，install命令在编译源码后还会将可执行文件或库文件安装到约定的目录下。

- go install编译出的可执行文件以其所在目录名(DIR)命名
- go install将可执行文件安装到与src同级别的bin目录下，bin目录由go install自动创建
- go install将可执行文件依赖的各种package编译后，放在与src同级别的pkg目录下



#### 22.go的并发模式

**生产者消费者模型**

​        并发编程中最常见的例子就是生产者消费者模式，该模式主要通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度。简单地说，就是生产者生产一些数据，然后放到成果队列中，同时消费者从成果队列中来取这些数据。这样就让生产消费变成了异步的两个过程。当成果队列中没有数据时，消费者就进入饥饿的等待中；而当成果队列中数据已满时，生产者则面临因产品挤压导致CPU被剥夺的下岗问题。

 **发布订阅模型**

​        发布订阅（publish-and-subscribe）模型通常被简写为pub/sub模型。在这个模型中，消息生产者成为发布者（publisher），而消息消费者则成为订阅者（subscriber），生产者和消费者是M:N的关系。在传统生产者和消费者模型中，是将消息发送到一个队列中，而发布订阅模型则是将消息发布给一个主题。

​        在发布订阅模型中，每条消息都会传送给多个订阅者。发布者通常不会知道、也不关心哪一个订阅者正在接收主题消息。订阅者和发布者可以在运行时动态添加，是一种松散的耦合关系，这使得系统的复杂性可以随时间的推移而增长。在现实生活中，像天气预报之类的应用就可以应用这个并发模式。 

 

### 二、操作系统方面（Linux系统）





### 三、网络知识

#### 1.tcp与udp  四次挥手 三次握手原理

> 为什么连接的时候是三次握手，关闭的时候却是四次握手？
>
> 答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

三次握手：

主动连接方（客户端）发送SYN标志位。

被动连接方（服务器）接收SYN标志位，同时回复ACK应答标志位。

主动连接方（客户端）发送ACK应答标志位。三次握手建立完成。

四次挥手：

主动断开连接方（客户端）发送FIN标志位。

被动断开连接方（服务器）回复ACK标志位。 半关闭完成。

被动断开连接方（服务器）发送FIN标志位。

主动断开连接方（客户端）回复ACK标志位。 四次挥手完成。



#### 2.简述OSI七层模型 和 TCP/IP四层模型。

OSI七层模型 ： 物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。

TCP/IP四层模型：数据链路层、网络层、传输层、应用层。



#### 3.描述简单的http请求协议  和  http应答协议。

http请求协议：                                                                     http应答协议：

​	GET / HTTP/1.1                                                                     HTTP/1.1 200 ok
	Host:127.0.0.1:8000                                                            Content-Length: 10
	(空行)                                                                                  (空行)

​                                                                                                        数据内容

请求报文和响应报文都是由以下4部分组成

1.请求行

2.请求头

3.空行

4.消息主体

#### 4.列举 TCP 与 UDP 区别， 要求至少 5点以上。

| tcp        | udp        |
| ---------- | ---------- |
| 面向连接       | 面向无连接      |
| 要求系统资源较多   | 要求系统资源较少   |
| TCP程序结构较复杂 | UDP程序结构较简单 |
| 数据传输使用流式   | 数据传输使用数据报式 |
| 保证数据准确性    | 不保证数据准确性   |
| 保证数据顺序     | 不保证数据顺序    |
| 通讯速度较慢     | 通讯速度较快     |

​			

#### 5.简述网络应用程序B/S、C/S设计模式优缺点及使用场景：

B/S模式：浏览器(Browser)/服务器(Server)模式。

```
优点：开发量较小、不受平台限制。

缺点：网络应用支持受限、不能缓存大量数据、协议选择不灵活。
```

C/S模式：客户机(client)/服务器(server)模式。

```
优点：提高数据传输效率、协议选择灵活。

缺点：工作量较大、对用户安全性构成威胁、受平台限制。
```



#### 6. 从打开浏览器输入url到显示网页，这当中发生了什么？	

1. DNS解析
2. 建立TCP连接
3. 浏览器发送HTTP请求报文
4. 服务器处理请求并返回HTTP响应报文
5. 浏览器解析渲染页面
6. 断开连接



#### 7.进程，线程，协程，go程的区别

1.  进程、线程、协程概念性区别

   对于进程、线程，都是有内核进行调度，有CPU时间片的概念，进行抢占式调度（有多种调度算法）。

   对于协程(用户级线程)，这是对内核透明的，也就是系统并不知道有协程的存在，是完全由用户的程序自己调度的，因为是由用户程序自己控制，那么就很难像抢占式调度那样做到强制的CPU控制权切换到其他进程/线程，通常只能进行协作式调度，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到。

2.  goroutine 和协程区别

   本质上，goroutine 就是协程。 不同的是，Golang 在 runtime、系统调用等多方面对 goroutine 调度进行了封装和处理，当遇到长时间执行或者进行系统调用时，会主动把当前 goroutine 的CPU (P) 转让出去，让其他 goroutine 能被调度并执行，也就是 Golang 从语言层面支持了协程。

进程：**进程**是“程序执行的一个实例” ，担当分配系统资源的实体。进程创建必须分配一个完整的独立地址空间。 

线程：轻量级的进程，本质仍是进程 (Linux下) ，**线程**（英语**thread**）是操作系统能够进行运算调度的最小单位 。线程是进程的一个执行流，独立执行它自己的程序代码。 

协程：coroutine。也叫轻量级线程。 一个线程中可以有任意多个协程，但某一时刻只能有一个协程在运行，**多个协程分享该线程分配到的计算机资源**。 

go程：goroutine是Go语言并行设计的核心，有人称之为go程。 goroutine说到底其实就是协程，它比线程更小，十几个goroutine可能体现在底层就是五六个线程，Go语言内部帮你实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存(大概是4~5KB)，当然会根据相应的数据伸缩。也正因为如此，可同时运行成千上万个并发任务。goroutine比线程更易用、更高效、更轻便。 



#### 8.实际开发中，怎么处理tcp粘包？

TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

出现粘包现象的原因是多方面的，它既可能由发送方造成，也可能由接收方造成。



**(1)发送固定长度的消息**

对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满；

**(2)把消息的尺寸与消息一块发送**

对于接收方引起的粘包，则可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象；

**(3)使用特殊标记来区分消息间隔**

由接收方控制，将一包数据按结构字段，人为控制分多次接收，然后合并，通过这种手段来避免粘包

同步标记分布接受

#### 9.WebSocket 

WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行**全双工通讯**的协议。

WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。

在 WebSocket API 中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。

现在，很多网站为了实现推送技术，所用的技术都是 Ajax 轮询。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。

HTML5 定义的 WebSocket 协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。

WebSocket 协议本质上是一个基于 TCP 的协议。

为了建立一个 WebSocket 连接，客户端浏览器首先要向服务器发起一个 HTTP 请求，这个请求和通常的 HTTP 请求不同，包含了一些附加头信息，其中附加头信息"Upgrade: WebSocket"表明这是一个申请协议升级的 HTTP 请求，服务器端解析这些附加的头信息然后产生应答信息返回给客户端，客户端和服务器端的 WebSocket 连接就建立起来了，双方就可以通过这个连接通道自由的传递信息，并且这个连接会持续存在直到客户端或者服务器端的某一方主动的关闭连接。

#### 10.输入网址到页面返回

1. 浏览器会开启一个线程来处理这个请求，对URL分析判断如果是http协议就按照Web方式来处理；
2. 调用浏览器内核中的对应方法，比如WebView中的loadUrl方法；
3. 通过DNS解析获取网址的IP地址，设置UA等信息发出第二个GET请求；
4. 进行HTTP协议会话，客户端发送报头（请求报头）
5. 进入到web服务器上的WebServer
6. 进入部署好的后端应用，找到对应的请求处理；
7. 处理结束回馈报头，此处如果浏览器访问过，缓存上有对应的资源，会与服务器最后修改时间对比，一致则返回304；
8. 浏览器开始下载html文档（响应报头，状态码200），同时使用缓存，
9. 文档树开始建立，根据标记请求所需制定的MIME类型文件同事设置了cookie；
10. 页面开始渲染DOM，JS根据DOM API操作DOM，执行时间的绑定等，页面显示完成。



#### 11.tcp长短连接的区别

       当网络通信时采用TCP协议时，在真正的读写操作之前，server与client之间必须建立一个连接，当读写操作完成后，双方不再需要这个连接时它们可以释放这个连接，连接的建立是需要三次握手的，而释放则需要4次挥手，所以说每个连接的建立都是需要资源消耗和时间消耗的 

**长连接**：

​       所谓长连接，指在一个TCP连接上可以连续发送多个数据包，在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持（不发生RST包和四次挥手）。      

​      连接→数据传输→保持连接(心跳)→数据传输→保持连接(心跳)→……→关闭连接（一个TCP连接通道多个读写通信）；       这就要求长连接在没有数据通信时，定时发送数据包(心跳)，以维持连接状态；

​      TCP保活功能，保活功能主要为服务器应用提供，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保活功能就是试图在服务器端检测到这种半开放的连接。

​       如果一个给定的连接在两小时内没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：

1. 客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保活定时器复位。
2. 客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。
3. 客户主机崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接。
4. 客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探查的响应。

**短连接**：

​      短连接是指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接（管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段）；

​     连接→数据传输→关闭连接；

**应用场景**：

​        长连接多用于操作频繁（读写），点对点的通讯，而且连接数不能太多情况，。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

​       而像WEB网站的http服务一般都用短链接（http1.0只支持短连接，1.1keep alive 带时间，操作次数限制的长连接），因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连好；

​       在长连接中一般是没有条件能够判断读写什么时候结束，所以必须要加长度报文头。读函数先是读取报文头的长度，再根据这个长度去读相应长度的报文。



### 四、beego框架

#### 1.简单介绍一下beego框架

beego作者是谢孟军，是go语言开发的web框架，它可以用来快速开发web应用，是典型的MVC结构，底层设计借鉴了python的tornado、sinatra 和 flask 框架（如果没有接触过python的同学最好不要说这个），内部包含很多模块，例如session模块，路由模块，orm模块等，让我们在开发中方便很多。



#### 2.beego框架的过程中觉得框架的优缺点是哪些

beego的优点是功能模块多，自动化编译，学习简单，上手快，开发速度快并且支持高并发。

缺点是：在controller里面集成了太多功能，导致controller臃肿。耦合度太高，采用的分文件编写，使代码看起来更具有模块化。



#### 3.简单介绍一下MVC架构/结构

MVC是指Model（模型）,View（视图）,Controller（控制器）。我们在项目开发的过程中，一般把数据库有关的操作都写在Model层，把页面显示的内容都放在View(视图)层，把主要的业务逻辑放在Controller(控制器)层。并且是通过Contoller(控制器)联通Model和View。通过这种分层操作，可以把不同的业务处理放在不同的地方，很好的实现了代码的解耦合。



#### 4.简单介绍一下beego中渲染和跳转的区别

渲染和跳转都能够实现页面的跳转，但是有一些区别。

1.URL显示不同：渲染方式跳转页面URL地址不变，跳转URL地址发生改变

2.本质区别：渲染本质上就是获取数据，并把数据在页面展示，最后把组装好的页面返回给浏览器。跳转是后台收到请求，返回给浏览器一个状态码和资源路径，浏览器再次发送了一次get请求。

3.适用场景不同：渲染一般用在页面第一次加载的时候。跳转用在两个页面之间的切换。



#### 5.简单介绍一下beego开发中cookie和session的区别

1.cookie把数据存储在客户端（网站的客户端是浏览器），session把数据存储在服务器。

2.session数据的安全系数比cookie高。

3.生命周期不同，在beego中我们用的一般是用临时session，生命周期是随着浏览器关闭而结束，cookie的生命周期是可以设置的，随着设置时间的结束而结束。



#### 6.项目中图片文件是如何存储的？请简单介绍一下

项目中图片文件用的是FastDFS存储。fastDFS是C++写的一个文件存储服务器，主要分为client，tracker，storage三块内容。当文件上传的时候，client先去查询tracker服务器，tracker服务器返回给client可用的strorage服务器信息，client根据返回的信息把文件上传到storage服务器，storage服务器返回给用户一个凭证。后期用户可以根据这个凭证来fastDFS中获取上传的文件。



#### 7.beego一共包含八大模块

cache   config   context   httplibs   logs   orm   session   toolbox

beego 是基于八大独立的模块构建的，是一个高度解耦的框架。

可以使用 cache 模块来做你的缓存逻辑；

使用日志模块来记录你的操作信息；

使用 config 模块来解析你各种格式的文件。

httplib 库主要用来模拟客户端发送 HTTP 请求

grace模块是beego新增的一个独立支持热重启的模块  

上下文模块主要是针对 HTTP 请求中，request 和 response 的进一步封装，他包括用户的输入和输出，用户的输入即为 request，context 模块中提供了 Input 对象进行解析，用户的输出即为 response，context 模块中提供了 Output 对象进行输出。 

核心工具模块（toolbox）中的几个功能：健康检查、性能调试、访问统计、计划任务。 

i18n 模块主要用于实现站点或应用的国际化功能，实现多语言界面与反馈，增强用户体验。像 Go Walker 和 beego 官网即是采用了该模块实现了中文与英文的双语界面。 

### 五、docker

#### 1.docker是什么？

​	Docker是一个开源的容器引擎，它基于LCX容器技术，使用Go语言开发。

​	源代码托管在Github上，并遵从Apache2.0协议。

​	Docker采用C/S架构，其可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。

​	Docker就是一种快速解决生产问题的一种技术手段,开发，运行和部署应用程序的开放管理平台。

​	开发人员能利用docker 开发和运行应用程序

​	运维人员能利用docker 部署和管理应用程序



#### 2.docker与虚拟机的区别

容器与虚拟机的相同点：

- 容器和虚拟机一样，都会对物理硬件资源进行共享使用。
- 容器和虚拟机的生命周期比较相似（创建、运行、暂停、关闭等等）。
- 容器中或虚拟机中都可以安装各种应用，如redis、mysql、nginx等。也就是说，在容器中的操作，如同在一个虚拟机(操作系统)中操作一样。
- 同虚拟机一样，容器创建后，会存储在宿主机上：linux上位于/var/lib/docker/containers下

容器与虚拟机的不同点==注意：容器并不是虚拟机，但它们有很多相似的地方==

- 虚拟机的创建、启动和关闭都是基于一个完整的操作系统。一个虚拟机就是一个完整的操作系统。而容器直接运行在宿主机的内核上，其本质上以一系列进程的结合。
- 容器是轻量级的，虚拟机是重量级的。首先容器不需要额外的资源来管理，虚拟机额外更多的性能消耗；其次创建、启动或关闭容器，如同创建、启动或者关闭进程那么轻松，而创建、启动、关闭一个操作系统就没那么方便了。
- 也因此，意味着在给定的硬件上能运行更多数量的容器，甚至可以直接把Docker运行在虚拟机上。



#### 3.docker-compose是什么？

docker-compose 是用来做docker 的多容器控制

docker-compose 是一个用来把 docker 自动化的东西。

有了 docker-compose 你可以把所有繁复的 docker 操作全都一条命令，自动化的完成。



#### 4.什么是Dockerfile

Dockerfile类似于我们学习过的脚本，将我们在上面学到的docker镜像，使用自动化的方式实现出来。



### 六、微服务

#### 1.什么是微服务

​        微服务架构风格是将单个应用程序作为一组小型服务开发的方法，每个服务程序都在自己的进程中运行，并与轻量级机制（通常是HTTP资源API）进行通信,我们项目中在服务直接使用的是gRPC的通信方式。这些服务是围绕业务功能构建的。可以通过全自动部署机器独立部署。这些服务器可以用不同的编程语言编写，使用不同的数据存储技术，并尽量不用集中式方式进行管理 

#### 2.项目开发过程中用到了那些技术？

微服务插件式框架go-micro

服务治理工具-consul

Google出品rpc通信框架-grpc

Google出品通信传输协议格式 protobuf

路由处理库 github.com/julienschmidt/httprouter

关系型数据库mysql

缓存型非关系数据库redis

图片服务器 fast-dfs + nginx

容器化 docker

#### 3.微服务如何拆分?

- 服务职责尽量单一化
- 服务的粒度适中
- 考虑团队的结构
- 以业务模型作为切入点
- 演进式拆分
- 避免环形依赖和双向依赖问题

#### 4.数据如何存储?

整个项目主要存储有3个方面

1. 图片服务器进行商品图片的存储 
2. 关系型数据库进行业务相关数据存储
3. redis缓存数据库的使用方向有两个

​      第一方向:为了避免关系数据库的频繁查询可以将,查询频率高的数据查询出来后短期存入缓存数据.

​      第二方向:session处理通过拼接key存储和获取当前用户独立的登录信息

#### 5.服务之间是如何进行通讯的?

微服务直接是通过gRPC框架进行通信,跨平台通讯格式为Protobuf

#### 6.为什么使用grpc通讯方式?

第一micro 默认支持与RPC通讯协议,并且附有grpc插件包

第二gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动端,gRPC基于 HTTP/2标准设计，带来诸如双向流、流控、头部压缩、单 TCP连接上的多复用请求等特性。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。

第三gRPC默认使用protoBuf，这是 Google开源的一套成熟的结构数据序列化机制.在配合使用下,在跨平台,跨语言,跨设备等情况的支持都比较好,并且现在谷歌最新的api已经开始推出gRPC接口,可以很轻松的讲Google功能集成到项目当中

#### 7.Protobuf有什么优点?

​      Protobuf是google的protocol buffer的简称.是一款结构化数据存储格式,可以平台无关、语言无关、可扩展，可用于通讯协议和数据存储,并且官方给出了C++,java,python,go等主流语言的支持.

​      prtobuf适合高性能，对响应速度有要求的数据传输场景。因为profobuf是二进制数据格式，需要编码和解码。数据本身不具有可读性。因此只能反序列化之后得到真正可读的数据。

1.灵活（方便接口更新）、高效（效率经过google的优化，传输效率比普通的XML等高很多）；

2.易于使用；开发人员通过按照一定的语法定义结构化的消息格式，然后送给命令行工具，工具将自动生成相关的类，可以支持[Java](http://lib.csdn.net/base/javaee)、c#、c++、[Go](http://lib.csdn.net/base/go) 和[Python](http://lib.csdn.net/base/python)等语言环境。通过将这些类包含在项目中，可以很轻松的调用相关方法来完成业务消息的序列化与反序列化工作。

3.语言支持；原生支持[Java](http://lib.csdn.net/base/javaee)、c#、c++、[Go](http://lib.csdn.net/base/go) 和Python

#### 8.Consul是什么?

Consul一个用于实线分布式系统的微服务治理,服务发现的开源工具.

Micro框架创建的微服务在启动之后,会与consul进行网络连接并进行通讯,将当前服务注册到consul当中,注册后就可以进行服务发现了

consul会根据同一类型的健康服务进行轮询访问从而达到负载均衡的效果 

微服务项目每个服务可以启动多个,并且注册到consul当中,如果同类服务中的1个服务挂掉了.那么consul会在健康检查发现服务挂掉后就停止对其进行访问,如果健康检查发现服务恢复后,会再次恢复对其访问

​      Consul的集群通常是有server和client两个角色,server端在一个集群中一般设定3个或者5个,客户端根据服务的数量可以控制在3-8个.

​      每台主机创建1个consul的角色,server可以放在公司自己的实体主机下,client可以运行在云服务器当中.



### 七、数据库相关

#### 1.Redis多线程查询？

使用redis作为缓存已经很久了，redis是以单进程的形式运行的，命令是一个接着一个执行的，有个键，假设名称为`myNum`，里面保存的是阿拉伯数字，假设现在值为1，存在多个连接对`myNum`进行操作的情况，这个时候就会有并发的问题。redis中也是有事务的，可以利用隔离性，原子性，开启事务之后，会执行完当前连接的所有命令直到遇到exec命令，才处理其他连接的命令。redis还有一个`watch`命令，这个命令可以解决这个问题，看下面的例子，对一个键执行watch，然后执行事务，由于watch的存在，他会监测键`a`，当`a`被修该之后，后面的事务就会执行失败，这就确保了多个连接同时来了，都监测着`a`，只有一个能执行成功，其他都返回失败。



#### 2.Redis有序集合查询前十个？

```
zrange key start stop//zrange key 0 9,0是起始下标，9是结束下标。
```



#### 3.Memcche与Redis的区别

Memcached是以LiveJurnal旗下Danga Interactive公司的Bard Fitzpatric为首开发的高性能分布式内存缓存服务器。其本质上就是一个内存key-value数据库，但是不支持数据的持久化，服务器关闭之后数据全部丢失

Redis是一种高性能的Key-Value，Nosql数据库，可以用来做缓存(ehcache/memcached)——redis的所有数据是放在内存中的（内存数据库）；Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。

Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型

#### 4.mysql索引有哪几种

1.虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。

2.建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快。

Memory存储引擎可以选择Hash或BTree索引，Hash索引只能用于=或<=>的等式比较。

1、普通索引：create index on Tablename(列的列表)

alter table TableName add index (列的列表)

create table TableName([...], index [IndexName] (列的列表)

2、唯一性索引：create unique index

alter ... add unique

主键：一种唯一性索引，必须指定为primary key

3、全文索引：从3.23.23版开始支持全文索引和全文检索，FULLTEXT，

可以在char、varchar或text类型的列上创建。

4、单列索引、多列索引：

多个单列索引与单个多列索引的查询效果不同，因为：

执行查询时，MySQL只能使用一个索引，会从多个索引中选择一个限制最为严格的索引。

5、最左前缀(Leftmost Prefixing)：多列索引，例如：fname_lname_age索引，以下的搜索条件MySQL都将使用

fname_lname_age索引：firstname,lastname,age；firstname,lastname；firstname，其他情况将不使用。

#### 5.乐观锁、悲观锁

> 在实际生产环境里边,如果并发量不大且不允许脏读，可以使用悲观锁解决并发问题；但如果系统的并发非常大的话,悲观锁定会带来非常大的性能问题,所以我们就要选择乐观锁定的方法. 

为什么需要锁（并发控制）？

　　在**多用户环境**中，在同一时间可能会有多个用户更新相同的记录，这会产生冲突。这就是著名的并发性问题。

**典型的冲突**有：

- **丢失更新**：一个事务的更新覆盖了其它事务的更新结果，就是所谓的更新丢失。例如：用户A把值从6改为2，用户B把值从2改为6，则用户A丢失了他的更新。
- **脏读**：当一个事务读取其它完成一半事务的记录时，就会发生脏读取。例如：用户A,B看到的值都是6，用户B把值改为2，用户A读到的值仍为6。

为了解决这些并发带来的问题。 我们需要引入并发控制机制。

　　**悲观锁：假定会发生并发冲突，**屏蔽一切可能违反数据完整性的操作。[1]

​        需要使用数据库的锁机制，比如SQL SERVER 的TABLOCKX（排它表锁） 此选项被选中时，SQL  Server  将在整个表上置排它锁直至该命令或事务结束。这将防止其他进程读取或修改表中的数据。 

​        我们在查询的时候使用了with (UPDLOCK)选项,在查询记录的时候我们就对记录加上了更新锁,表示我们即将对此记录进行更新. 注意更新锁和共享锁是不冲突的,也就是其他用户还可以查询此表的内容,但是和更新锁和排它锁是冲突的.所以其他的更新用户就会阻塞. 

　　**乐观锁：假设不会发生并发冲突，**只在提交操作时检查是否违反数据完整性。[1] 乐观锁不能解决脏读的问题。乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。那么我们如何实现乐观锁呢，一般来说有以下2种方式：

　　1.使用**数据版本**（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。

​      2.乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型**使用时间戳（timestamp）**, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。 

#### 6.redis的数据类型

redis提供五种数据类型：string，hash，list，set及zset(sorted set)。 

#### 7.redis的缓存策略

noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。 大多数写命令都会导致占用更多的内存(有极少数会例外, 如 DEL )。

allkeys-lru: 所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。

volatile-lru: 只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。

allkeys-random: 所有key通用; 随机删除一部分 key。

volatile-random: 只限于设置了 expire 的部分; 随机删除一部分 key。

volatile-ttl: 只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。

expire: expire是设置redis过期时间的命令

#### 8.redis如何提高性能

解决方案，那就是pipeline机制，原理还是一样，将命令集整合起来通过
一条request请求一起送过去，由redis内部fake出一个client做批量执行操作



#### 9.mysql优化

1. ##### 使用EXPLAIN

> 使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈。

```sql
使用方法：
Explain sql语句
```

Explain的作用：

1. 表的读取顺序
2. 数据读取操作的操作类型
3. 哪些索引可以使用
4. 那些索引被实际使用
5. 表之间的引用
6. 买张表有多少行被优化器查询

执行计划包含的信息：

![image](https://img-blog.csdn.net/20170509232741017?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd3VzZXl1a3Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

1. **==id(重要字段)==**

   > select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序

   三种情况：

   - id相同，执行顺序由上至下
   - id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行
   - id不相同，值越高的越先执行

2. select_type

   > 查询的类型，主要是用于区别普通查询、联合查询、子查询等的复杂查询。

   - SIMPLE：简单的select查询，查询中不包含子查询或者UNION
   - PRIMARY:查询中包含任何复杂的子部分，最外层查询则被标记为
   - SUBQUERY：在select或者where列表中包含了子查询
   - DERIVED：在from列表中包含的子查询被标记为DERIVED（衍生）MySQL会递归执行这些子查询，把结果放在临时表里。
   - UNION：若在第二个select出现在UNION之后，则被标记为UNION：若UNION包含在fron子句的子查询中外层select将被标记为：DERIVED
   - UNION RESULT：从UNION表获取结果的select

3. table

   > 这一行数据是关于那张表的

4.  **==type(重要字段)==**

   > 显示查询使用了何种类型，从最好到最差依次是 system>const>eq_ref>ref>range>index>ALL

   - system:表只有一行记录（等于系统表），这是const类型的特例，平时不会出现，这个也可以忽略不计
   - const：表示通过索引一次就找到了，const用于比较primary key或者unique索引。因为只匹配一行数据，所以很快
   - eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配，常见于主键或者唯一索引扫描
   - ref：为唯一性索引扫描，返回匹配某个单独值所在行，本质上也是一种索引访问，他返回所有匹配某个单独值的行，然而，他可能会找到多个符合条件的行，所以他应该属于查找和扫描混合体
   - range：只检索给定范围的行，使用一个索引来选择执行。key列显示使用了哪个索引，一般就是在你的where语句中出现between，<,>,in等的查询。这种范围扫描索引扫描比全表扫描要好，因为它值需要开始于索引的某一值，而结束于另一点，不用扫描全部索引。
   - index：index与all区别为index类型只遍历索引树。通常比ALL快，因为索引文件通常比数据文件小
   - all：将遍历全表以找到匹配的行。
   - **一般来说，要保证查询至少达到range级别，最好能达到ref。**

5. possible_keys

   > 显示可能应用在这张表中的索引，一个或多个。查询设计到的字段上若存在索引，则该索引将被列出， **但不一定被查询实际使用**

6. **==key(重要字段)==**

   > 实际使用的索引。如果为NULL，则没有使用索引。 **查询中若使用覆盖索引，则该索引仅出现在key列表中**

7. key_len

   > 表示索引中使用的字节数，可通过该列计算查询中使用的索引长度。在不损失精确性的情况下，长度越短越好，key_len显示的值为索引字段的最大可能长度， **并非实际使用长度** ，即key_len是根据定义计算而得，不是通过表内检索出的。

8. ref

   > 显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或者常量被用于查找索引列上的值。

9. **rows(重要字段)**

   > 根据表统计信息及索引选用情况，大致估算出找到所需记录数所需要读取的行数

10. **==Extra(重要字段)==**

   > 包含不适合在其他列中显示但十分重要的额外信息

   - Using filesort： 说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。mysql中无法利用索引完成的排序操作称为“文件排序”。
   - Using temporary： 使用临时表保存中间结果，mysql在对查询结果排序时使用临时表。常见于排序order by 和分组查询group by。
   - Using index：表示相应的select操作中使用了覆盖索引（Covering Index），避免了表的数据行，效率不错！如果同时出现 **using where**，表明索引被用来执行索引键值的查找。如果没有同时出现 **using where** ，表明索引用来读取数据而非执行查找动作。
   - Using where：表明使用了where过滤。
   - using join buffer：使用了连接缓存。
   - impossible where：where子句的值总是false，不能用来获取任何元组。
   - select tables optimized away：在没有group by子句的情况下，基于索引优化MIN/MAX操作或者对于MyISAM存储引擎优化COUNT（*）操作，不必等到执行阶段在进行计算，查询自行计划生成的阶段完成优化。
   - distinct：优化distinct操作在找到第一匹配的元组后即停止同样值的动作。



2. ##### 索引优化

   1. 索引失效
      - 全值匹配我最爱
      - 最佳左前缀法则：如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。
      - 不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描
      - 存储引擎不能使用索引中范围条件右边的列
      - 尽量使用覆盖索引（只访问索引的查询（索引列和查询列一致）），减少select*
      - mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描
      - is null，is not null也无法使用索引
      - like以通配符开头（‘%abc...’）mysql索引失效会变成全表扫描的操作 **%写在右边会不会引起索引失效**
      - 字符串不加单引号索引失败
      - 少用or，用它来连接时索引会失效
      - 问题解决like‘%字符串%’时索引不被使用的方法，**运用覆盖索引避免全表扫描**



### 八、代码题

#### 1.这段程序会隐含什么问题？

```js
func xxx（）｛
	var wg sync.WaiGroup

	for i:=0;i<2;i++{
  		wg.Add(1)
        go func(id int){
          //do something work...
          wg.done()
        }(i)
	}
	wg.Wait()
｝

```

少一个defer，可能会出现do something work里面的工作还没做完，计数就减一，然后直接运行wg.wait之后的代码了



#### 2.下面程序应该输出什么？请在Print后写出编号即可

```go
func main(){
  f()
  fmt.Println("Returned normally from f.")
}

func f(){
  defer func(){
    if r:=recover();r!=nil{
      fmt.Println("Returned in f",r)
    }
  }()
  
  fmt.Println("Calling g.")
  g()
  fmt.Println("Returned normally from g.")
}

func g(){
  panic("ERROR")
}
//1.Calling g.
//2.Returned in f",ERROR
//3.Returned normally from f.
```





### 九、git常用命令

#### 安装及配置：

Ubuntu下安装：`sudo apt-get install git`
配置用户名：`git config --global user.name "你的名字"`
配置e-mail：`git config --global user.email "你的邮箱@xx.com"`

#### 与添加有关的：

将当前目录变为仓库：`git init`
将文件添加到暂存区：`git add 文件名 [可选：另一个文件名]`
将暂存区提交到仓库：`git commit –m "描述"`

#### 与查询有关的：

查询仓库状态：`git status`
比较文件差异（请在git add之前使用）：`git diff 文件名`
查看仓库历史记录(详细)：`git log`
查看仓库历史记录(单行)：`git log --pretty=online` 或 `git log --online`
查看所有版本的commit ID：`git reflog`

#### 与撤销有关的：

撤销工作区的修改：`git checkout -- 文件名`
撤销暂存区的修改：`git reset HEAD 文件名`
回退到历史版本：`git reset --hard 该版本ID`
回退到上个版本：`git reset --hard HEAD^`
上上版本是`HEAD^^`，也可用`HEAD~2`表示，以此类推

#### 与标签有关的：

为当前版本打标签：`git tag 标签名`
为历史版本打标签：`git tag 标签名 该版本ID`
指定标签说明：`git tag –a 标签名 –m "标签说明" [可选：版本ID]`
查看所有标签：`git tag`
查看某一标签：`git show 标签名`
删除某一标签：`git tag –d 标签名`

#### 与GitHub有关的：

先有本地库，后有远程库，将本地库push到远程库

关联本地仓库和GitHub库：`git remote add origin 网站上的仓库地址`
第一次将本地仓库推送到GitHub上：`git push –u origin master`

先有远程库，后有本地库，从远程库clone到本地库

从远程库克隆到本地：`git clone 网站上的仓库地址`

### 十、gin

#### 1.gin平滑重启

- 不关闭现有连接（正在运行中的程序）
- 新的进程启动并替代旧进程
- 新的进程接管新的连接
- 连接要随时响应用户的请求，当用户仍在请求旧进程时要保持连接，新用户应请求新进程，不可以出现拒绝请求的情况
- make restart 

#### 2.gin中间件的作用

Gin中间件的作用有两个：

1. Web请求到到达我们定义的HTTP请求处理方法之前，拦截请求并进行相应处理(比如：权限验证，数据过滤等)，这个可以类比为`前置拦截器`或`前置过滤器`，
2. 在我们处理完成请求并响应客户端时，拦截响应并进行相应的处理(比如：添加统一响应部头或数据格式等)，这可以类型为`后置拦截器`或`后置过滤器`。

####  3.采用的日志包

日志包 `lexkong/log`是笔者根据开发经验，并调研 GitHub 上的 开源log 包后封装的一个日志包，也是笔者所在项目使用的日志包。它参考华为 `paas-lager`，做了一些便捷性的改动，功能完全一样，只不过更为便捷。相较于 Go 的其他日志包，该日志包有如下特点：

- 支持日志输出流配置，可以输出到 stdout 或 file，也可以同时输出到 stdout 和 file
- 支持输出为 JSON 或 plaintext 格式
- 支持彩色输出
- 支持 log rotate 功能
- 高性能

####  4.beego框架与gin框架的区别

**1.对mvc的支持**

beego支持完整的mvc

M:Model,beego orm,把数据库数据变成object

特性

- 支持go的所有类型存储
- 更简洁的curd风格
- 完整实现了健壮的ORM

支持的数据库

- mysql、postgresql、sqlite3

V:View模板

特性

- 支持静态文件处理
- 支持模板的处理
- 支持模板的分页处理

C:各种业务逻辑处理

特性

- 路由控制
- 控制器函数
- 支持csrf
- session
- 错误处理和日志功能

gin不支持完整的mvc

- 需要开发者自己实现mvc

特性

- 支持HTML渲染和模板
- 静态文件服务
- 路由
- 不支持session

**2.对路由的支持**

Beego

支持正则路由

- 支持restful Controller路由

Gin

不支持正则路由

**3.适用场景**

Beego在业务方面较Gin支持更多

- 在业务更加复杂的项目，适用beego
- 在需要快速开发的项目，适用beego
- 在1.0的项目中，适用beego，因为项目初期对性能没太大要求

Gin在性能方面较beego更好

- 当某个接口性能遭到较大的挑战，考虑用Gin重写
- 如果项目的规模不大，业务相对简单，适用Gin





 快排的原理：

原理： 从一组数据中拿出一个数来，以此数据为标准，低于这个数据放到数据的左边，高于这个数据的数据放到右边。以此类推对数据做出排序

时间复杂度
o(nlogn)

m代表的递归次数
n=2^m T[1]  + mn

 

 

 

 